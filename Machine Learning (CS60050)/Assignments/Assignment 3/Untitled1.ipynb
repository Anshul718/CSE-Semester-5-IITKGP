{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\tName - Anshul Choudhary\n",
    "##########\tRoll - 17CS10005\n",
    "##########\tAssignment - 3 (AdaBoost)\n",
    "\n",
    "import numpy as np,numpy\n",
    "import math\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2150\n",
      "1363\n",
      "[ 216  742 1038 ... 1319 1426 1319]\n"
     ]
    }
   ],
   "source": [
    "###################Calling Functions################################\n",
    "#Loading data from the given csv file\n",
    "data = genfromtxt('data3_19.csv', delimiter=',', dtype = str)\n",
    "\n",
    "#Training Phase\n",
    "p = []\n",
    "indexArray = []\n",
    "replace = True\n",
    "D = data[1:,]\n",
    "for i in range(0,D.shape[0]):\n",
    "\tp.append(1/D.shape[0])\n",
    "\tindexArray.append(i)\n",
    "\n",
    "#Random Sampling\n",
    "randomSample = np.random.choice(indexArray,D.shape[0],replace,p)\n",
    "print(len(randomSample))\n",
    "print(len(set(randomSample)))\n",
    "print(randomSample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1st' 'adult' 'female' 'yes']\n",
      " ['3rd' 'adult' 'male' 'no']\n",
      " ['3rd' 'adult' 'female' 'yes']\n",
      " ...\n",
      " ['2nd' 'adult' 'male' 'no']\n",
      " ['crew' 'adult' 'male' 'no']\n",
      " ['2nd' 'adult' 'male' 'no']]\n"
     ]
    }
   ],
   "source": [
    "train = D[:]\n",
    "#print(train1.shape[0])\n",
    "for i in range(0,D.shape[0]):\n",
    "\ttrain[i] = D[randomSample[i]]\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1st', 'adult', 'female'],\n",
       "       ['3rd', 'adult', 'male'],\n",
       "       ['3rd', 'adult', 'female'],\n",
       "       ...,\n",
       "       ['2nd', 'adult', 'male'],\n",
       "       ['crew', 'adult', 'male'],\n",
       "       ['2nd', 'adult', 'male']], dtype='<U8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classWts = []\n",
    "y_array = []\n",
    "X = data[1:,0:3]\n",
    "# Extracting target class\n",
    "y = data[1:,3]\n",
    "y.shape = (X.shape[0],1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['yes'],\n",
       "       ['no'],\n",
       "       ['yes'],\n",
       "       ...,\n",
       "       ['no'],\n",
       "       ['no'],\n",
       "       ['no']], dtype='<U8')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class treeNode:\n",
    "\tdef __init__(self): \n",
    "\t\tself.label = \"\"\n",
    "\t\tself.next = None\n",
    "\t\tself.nodelist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entropy(TE_Y):\n",
    "\taccept_Y = TE_Y[numpy.where(TE_Y[:,0] == 'yes')]\t\t\t\t\t\t\t\t\t# classify into accept and reject cases\n",
    "\treject_Y = TE_Y[numpy.where(TE_Y[:,0] == 'no')]\n",
    "\tcount_accY = accept_Y.shape[0]\t\t\t\t\t\t\t\t\t\t\t\t\t\t# count accept cases\n",
    "\tcount_rejY = reject_Y.shape[0]\t\t\t\t\t\t\t\t\t\t\t\t\t\t# count reject cases\n",
    "\t\n",
    "\tcount = count_accY + count_rejY\n",
    "\tif(count ==0 ):\n",
    "\t\t return 0\n",
    "\tprob_accY = count_accY / (count)\t\t\t\t\t\t\t\t\t# accept probability\n",
    "\tprob_rejY = count_rejY / (count)\t\t\t\t\t\t\t\t\t# reject probability\n",
    "\treturn -(prob_accY * numpy.log(prob_accY)) - (prob_rejY * numpy.log(prob_rejY))\t\t# return entropy\n",
    "\n",
    "\n",
    "def Gain(TE,S,categ,index):\n",
    "\tn = TE.shape[0]\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# number of Training Examples\n",
    "\tsum = 0\n",
    "\tfor catg in categ:\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# calculate entropy for each case of 'categ' category(feature)\n",
    "\t\tsub_TE = TE[numpy.where(TE[:,index] == catg)]\n",
    "\t\tTE_Y = sub_TE[:,sub_TE.shape[1]-1]\n",
    "\t\tTE_Y.shape = (len(TE_Y),1)\n",
    "\t\tcount_Y = TE_Y.shape[0]\n",
    "\t\tsum += (count_Y/n) * Entropy(TE_Y)\n",
    "\n",
    "\treturn Entropy(S) - sum\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# return Gain\n",
    "\n",
    "def GenerateDecisionTree(TE,TE_X,TE_Y,categs,features,tab):\n",
    "\t\n",
    "\tfeat_count = TE_X.shape[1]\n",
    "\troot_node = Node()\n",
    "\n",
    "\tif(feat_count == 1):\t\t\t\t\t\t\t\t\t\t\t\t\t# case when there is only one feature left\n",
    "\t\tindex = 0\n",
    "\t\troot_node\n",
    "\n",
    "\t\tfor catg in categs[0]:\n",
    "\n",
    "\t\t\tsub_TE = TE[numpy.where(TE[:,index] == catg)]\t\t\t\t\t# TE's where this feature takes value catg\n",
    "\t\t\taccept_TE = sub_TE[numpy.where(sub_TE[:,1] == 'yes')]\t\t\t# corresponding accept TE\n",
    "\t\t\treject_TE = sub_TE[numpy.where(sub_TE[:,1] == 'no')]\t\t\t# corresponding reject TE\n",
    "\n",
    "\t\t\tif(accept_TE.shape[0] == 0 and reject_TE.shape[0] == 0):\t\t# if no such TE, do nothing\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tprint(tab + features[index] + \" = \" + catg + \": \",end = \" \")\t\n",
    "\n",
    "\t\t\tif(accept_TE.shape[0] > reject_TE.shape[0]):\t\t\t\t\t# if accept TE are more than reject TE \n",
    "\t\t\t\tprint(\"yes\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"no\")\n",
    "\t\n",
    "\telse:\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# case where more than one feature are left\n",
    "\t\tindex = 0\n",
    "\t\tmax_gain = 0\n",
    "\n",
    "\t\tfor i in range(feat_count):\t\t\t\t\t\t\t\t\t\t\t# find feature with maximum gain\n",
    "\t\t\tgain = Gain(TE,TE_Y,categs[i],i)\n",
    "\n",
    "\t\t\tif(gain > max_gain):\n",
    "\t\t\t\tmax_gain = gain\n",
    "\t\t\t\tindex = i\n",
    "\t\t\n",
    "\t\tfor catg in categs[index]:\t\t\t\t\t\t\t\t\t\t\t# generate tree for each value of max_gain feature\n",
    "\t\t\tsub_TE = TE[numpy.where(TE[:,index] == catg)]\n",
    "\t\t\tcount = sub_TE.shape[1]\n",
    "\n",
    "\t\t\tif(sub_TE.shape[0] == 0):\t\t\t\t\t\t\t\t\t\t# if corresponding TE's are 0, continue to next feature value\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\taccept_TE = sub_TE[numpy.where(sub_TE[:,count-1] == 'yes')]\t\t# accept TE's\n",
    "\t\t\treject_TE = sub_TE[numpy.where(sub_TE[:,count-1] == 'no')]\t\t# reject TE's\n",
    "\n",
    "\t\t\tif(accept_TE.shape[0] == 0):\t\t\t\t\t\t\t\t\t# when all TE's are of accept case\n",
    "\t\t\t\tprint(tab + features[index] + \" = \" + catg + \": no\")\t\t\n",
    "\t\t\t\tbreak\n",
    "\t\t\telif(reject_TE.shape[0] == 0):\t\t\t\t\t\t\t\t\t# when all TE's are of reject case\n",
    "\t\t\t\tprint(tab + features[index] + \" = \" + catg + \": yes\")\n",
    "\t\t\t\tbreak\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# get new TE's for further proceeding\n",
    "\t\t\tTE_new = numpy.delete(sub_TE , index, axis=1)\t\t\t\t\t# delete the feature cloumn that is already processed above\n",
    "\t\t\tcount = TE_new.shape[1]\n",
    "\t\t\tTE_X_new = TE_new[:,0:count - 1]\t\t\t\t\t\t\t\t# new TE conditions only\n",
    "\t\t\tTE_Y_new = TE_new[:,count-1]\t\t\t\t\t\t\t\t\t# new TE outputs only\n",
    "\t\t\tTE_Y_new.shape = (len(TE_Y_new),1)\n",
    "\t\t\tfeatures_new = numpy.delete(features,index)\t\t\t\t\t\t# new features without the feature processed above\n",
    "\t\t\tcategs_new = numpy.delete(categs,index)\t\t\t\t\t\t\t# new categorys without category of feature processed above\n",
    "\t\t\t\n",
    "\t\t\tprint(tab + features[index] + \" = \" + catg)\n",
    "\t\t\t\n",
    "\t\t\tGenerateDecisionTree(TE_new,TE_X_new,TE_Y_new,categs_new,features_new,tab + \"|\t\")  \t# recursive call for child nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################################################\n",
      "CLASSIFIER 1\n",
      "gender = female\n",
      "|\tage = adult\n",
      "|\t|\tpclass = 1st:  yes\n",
      "|\t|\tpclass = 2nd:  yes\n",
      "|\t|\tpclass = 3rd:  no\n",
      "|\t|\tpclass = crew:  yes\n",
      "|\tage = child\n",
      "|\t|\tpclass = 2nd:  yes\n",
      "|\t|\tpclass = 3rd:  no\n",
      "gender = male\n",
      "|\tpclass = 1st\n",
      "|\t|\tage = adult:  no\n",
      "|\t|\tage = child:  yes\n",
      "|\tpclass = 2nd\n",
      "|\t|\tage = adult:  no\n",
      "|\t|\tage = child:  yes\n",
      "|\tpclass = 3rd\n",
      "|\t|\tage = adult:  no\n",
      "|\t|\tage = child:  no\n",
      "|\tpclass = crew\n",
      "|\t|\tage = adult:  no\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n",
      "D:\\Installs\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "treeArray = []\n",
    "for k in range(1,2):\n",
    "\tprint(\"########################################################################\")\n",
    "\tprint(\"CLASSIFIER \" + str(k))\n",
    "\t#Extracting data labels and attributes\n",
    "\tlabels = data[0,0:3]\n",
    "\tattr = []\n",
    "\n",
    "\t\n",
    "\t#tab : to add necessary indentation\n",
    "\ttab = \"\"\n",
    "\n",
    "\t#Build decision tree\n",
    "\tX_train = train[:,0:3]\n",
    "\t\n",
    "\t#make list of all possible values of all attributes \n",
    "\tfor i in range(0,3):\n",
    "\t\tattr.append(np.unique(X[:,i]))\n",
    "\t#print(attr)\n",
    "\ty_train = train[:,3]\n",
    "\ty_t = train[:,3]\n",
    "\ty_train.shape = (X_train.shape[0],1)\n",
    "\troot = GenerateDecisionTree(train,X_train,y_train,attr,labels,tab)\n",
    "\tprint(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['crew' 'adult' 'male' 'yes']\n",
      " ['3rd' 'child' 'male' 'no']\n",
      " ['1st' 'child' 'male' 'yes']\n",
      " ...\n",
      " ['crew' 'adult' 'male' 'yes']\n",
      " ['1st' 'child' 'male' 'yes']\n",
      " ['2nd' 'adult' 'male' 'no']]\n",
      "########################################################################\n",
      "CLASSIFIER 1\n",
      "gender = female\n",
      "|\tpclass = 1st: yes\n",
      "gender = male\n",
      "|\tpclass = 1st\n",
      "|\t|\tage = adult:  no\n",
      "|\t|\tage = child:  yes\n",
      "|\tpclass = 2nd\n",
      "|\t|\tage = adult:  no\n",
      "|\t|\tage = child:  yes\n",
      "|\tpclass = 3rd\n",
      "|\t|\tage = adult:  no\n",
      "|\t|\tage = child:  no\n",
      "|\tpclass = crew\n",
      "|\t|\tage = adult:  no\n",
      "|\t|\tage = child:  yes\n",
      "Accuracy of the Classifier 1 is: \n",
      "0.7046511627906977\n",
      "########################################################################\n",
      "CLASSIFIER 2\n",
      "gender = female\n",
      "|\tpclass = 1st: yes\n",
      "gender = male\n",
      "|\tpclass = 1st\n",
      "|\t|\tage = adult:  no\n",
      "|\t|\tage = child:  yes\n",
      "|\tpclass = 2nd\n",
      "|\t|\tage = adult:  no\n",
      "|\t|\tage = child:  yes\n",
      "|\tpclass = 3rd\n",
      "|\t|\tage = adult:  no\n",
      "|\t|\tage = child:  no\n",
      "|\tpclass = crew\n",
      "|\t|\tage = adult:  no\n",
      "|\t|\tage = child:  yes\n",
      "Accuracy of the Classifier 2 is: \n",
      "0.5251162790697674\n",
      "########################################################################\n",
      "CLASSIFIER 3\n",
      "gender = female\n",
      "|\tpclass = 1st: yes\n",
      "gender = male\n",
      "|\tpclass = 1st: no\n",
      "Accuracy of the Classifier 3 is: \n",
      "0.012558139534883722\n",
      "########################################################################\n",
      "COMBINED CLASSIFIER \n",
      "Accuracy of the Combined Classifier is: \n",
      "0.6461538461538462\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "#Name - Nilesh Mandal\n",
    "#Roll - 17CS10031\n",
    "#Assignment - 3\n",
    "#*********Run With Python3***********\n",
    "####################################################################\n",
    "\n",
    "###############################BEGIN################################\n",
    "\n",
    "#Importing required libraries\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy import genfromtxt\n",
    "\n",
    "class Node:\n",
    "\tdef __init__(self): \n",
    "\t\tself.label = \"\"\n",
    "\t\tself.next = None\n",
    "\t\tself.nodelist = [] \n",
    "#To calculate entropy\n",
    "def Entropy(y):\n",
    "\tP = y[np.where(y[:,0] == 'yes')]\n",
    "\tN = y[np.where(y[:,0] == 'no')]\n",
    "\n",
    "\tp = P.shape[0]\n",
    "\tn = N.shape[0]\n",
    "\n",
    "\tif(p + n == 0):\n",
    "\t\treturn 0\n",
    "\tf_p = p / (p + n)\n",
    "\tf_n = n / (p + n)\n",
    "\n",
    "\tif(f_p == 0):\n",
    "\t\tf_p = 0.0000000001\n",
    "\tif(f_n == 0):\n",
    "\t\tf_n = 0.0000000001\n",
    "\t\t\n",
    "\tentropy = - (f_p * np.log(f_p)) - (f_n * np.log(f_n))\n",
    "\n",
    "\treturn entropy\n",
    "\n",
    "#X : the array with selected attribute\n",
    "#S : the parent array\n",
    "#attr : list of values of selected attribute\n",
    "#index : concerned column of attribute\n",
    "def Gain(X,S,attr,index):\n",
    "\tn = X.shape[0]\n",
    "\tsum = 0\n",
    "\tfor val in attr:\n",
    "\t\tA = X[np.where(X[:,index] == val)]\n",
    "\t\tl = A.shape[1]\n",
    "\t\ty = A[:,l-1]\n",
    "\t\tif(len(y) == 0):\n",
    "\t\t\tcontinue\n",
    "\t\ty.shape = (len(y),1)\n",
    "\t\tn_y = y.shape[0]\n",
    "\t\tsum += (n_y/n) * Entropy(y)\n",
    "\t\t#print(sum)\n",
    "\tgain = Entropy(S) - sum\n",
    "\treturn gain\n",
    "\n",
    "#Find max gain attribute\n",
    "#Make that root\n",
    "#For all possible values of that attribute,add a node\n",
    "#For each path,recurse and repeat the process with subset array\n",
    "#When only 1 attribute remains, assign the majority element('yes' or 'no') as the answer\n",
    "def recursiveTree(data,X,y,attr,labels,tab):\n",
    "\tmax_gain = 0\n",
    "\tindex = 0\n",
    "\tL = X.shape[1]\n",
    "\tnew_node = Node()\n",
    "\t#When only 1 attribute\n",
    "\tif(L == 1):\n",
    "\t\tnew_node.label = labels[index]\n",
    "\t\tfor val in attr[0]:\n",
    "\t\t\tcurr = Node()#male,female,etc\n",
    "\t\t\tcurr.label = val\n",
    "\t\t\tnew_node.nodelist.append(curr)\n",
    "\t\t\tA = data[np.where(data[:,index] == val)]\n",
    "\t\t\tl = A.shape[1]\n",
    "\t\t\tYES = A[np.where(A[:,1] == 'yes')]\n",
    "\t\t\tNO = A[np.where(A[:,1] == 'no')]\n",
    "\t\t\tprint(tab + labels[index] + \" = \" + val + \": \",end = \" \")\n",
    "\t\t\tif(YES.shape[0] == 0 and NO.shape[0] == 0):\n",
    "\t\t\t\tn_val = Node()\n",
    "\t\t\t\tn_val.label = \"yes\"\n",
    "\t\t\t\tnew_node.nodelist[len(new_node.nodelist) - 1].next = n_val\n",
    "\t\t\t\tprint(\"yes\")\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tif(YES.shape[0] > NO.shape[0]):\n",
    "\t\t\t\tn_val = Node()\n",
    "\t\t\t\tn_val.label = \"yes\"\n",
    "\t\t\t\tnew_node.nodelist[len(new_node.nodelist) - 1].next = n_val\n",
    "\t\t\t\tprint(\"yes\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tn_val = Node()\n",
    "\t\t\t\tn_val.label = \"no\"\n",
    "\t\t\t\tnew_node.nodelist[len(new_node.nodelist) - 1].next = n_val\n",
    "\t\t\t\tprint(\"no\")\n",
    "\t#More than 1 attribute\n",
    "\telse:\n",
    "\t\t#find attribute with max gain and store its column no. in 'index'\n",
    "\t\tfor i in range(0,L):\n",
    "\t\t\tgain = Gain(data,y,attr[i],i)\n",
    "\t\t\tif(gain > max_gain):\n",
    "\t\t\t   max_gain = gain\n",
    "\t\t\t   index = i\n",
    "\t\tnew_node.label = labels[index]\n",
    "\t\t#For all possible values of the max gain attribute \n",
    "\t\t#E.g for gender,iterate through male and female\n",
    "\t\tfor val in attr[index]:\n",
    "\t\t\tcurr = Node()#male,female,etc\n",
    "\t\t\tcurr.label = val\n",
    "\t\t\tnew_node.nodelist.append(curr)\n",
    "\t\t\tA = data[np.where(data[:,index] == val)]\n",
    "\t\t\tl = A.shape[1]\n",
    "\t\t\tif(A.shape[0] == 0):\n",
    "\t\t\t   continue\n",
    "\t\t\tYES = A[np.where(A[:,l-1] == 'yes')]\n",
    "\t\t\tNO = A[np.where(A[:,l-1] == 'no')]\n",
    "\t\t\tif(YES.shape[0] == 0):\t\t\t#if only 'no'\n",
    "\t\t\t   n_val = Node()\n",
    "\t\t\t   n_val.label = \"no\"\n",
    "\t\t\t   new_node.nodelist[len(new_node.nodelist) - 1].next = n_val\n",
    "\t\t\t   print(tab + labels[index] + \" = \" + val + \": no\")\n",
    "\t\t\t   break\n",
    "\t\t\telif(NO.shape[0] == 0):\t\t\t#if only 'yes'\n",
    "\t\t\t   n_val = Node()\n",
    "\t\t\t   n_val.label = \"yes\"\n",
    "\t\t\t   new_node.nodelist[len(new_node.nodelist) - 1].next = n_val\n",
    "\t\t\t   print(tab + labels[index] + \" = \" + val + \": yes\")\n",
    "\t\t\t   break\n",
    "\t\t\t\n",
    "\t\t\t#delete this attribute column to get the sub table in which we need to recurse\n",
    "\t\t\tdata_new = np.delete(A , index, axis=1)\n",
    "\t\t\tl = data_new.shape[1]\n",
    "\t\t\tX_new = data_new[:,0:l - 1]\n",
    "\t\t\ty_new = data_new[:,l-1]\n",
    "\t\t\ty_new.shape = (len(y_new),1)\n",
    "\t\t\tlabels_new = np.delete(labels,index)\n",
    "\t\t\tattr_new = np.delete(attr,index)\n",
    "\t\t\t\n",
    "\t\t\t#Printing current level\n",
    "\t\t\tprint(tab + labels[index] + \" = \" + val)\n",
    "\t\t\t#recursive call to print child levels\n",
    "\t\t\tnew_node.nodelist[len(new_node.nodelist) - 1].next = recursiveTree(data_new,X_new,y_new,attr_new,labels_new,tab + \"|\t\")\n",
    "\treturn new_node\n",
    "\n",
    "\n",
    "#For one row of test set\n",
    "#Return predicted y value\n",
    "def traverseTree(X,root,labels):\n",
    "\tif(root == None):\n",
    "\t\treturn \"\"\n",
    "\tif(len(root.nodelist) == 0):\n",
    "\t\tif(root.label == \"yes\" or root.label == \"no\"):\n",
    "\t\t\treturn root.label\n",
    "\t\telse:\n",
    "\t\t\treturn \"\"\n",
    "\ti = labels.index(root.label)\n",
    "\tfor var in root.nodelist:\n",
    "\t\tif(X[i] == var.label):\n",
    "\t\t\treturn traverseTree(X,var.next,labels)\n",
    "\treturn \"\"\n",
    "\n",
    "#For complete test set\n",
    "def runClassifier(X_test,root,labels):\n",
    "\ty_out = []\n",
    "\tfor i in range(0,X_test.shape[0]):\n",
    "\t\ty_out.append(traverseTree(X_test[i],root,labels))\n",
    "\treturn y_out\n",
    "\n",
    "#####AdaBOOST Funtions#############################\n",
    "\n",
    "#calculate weight of vote of a classifier\n",
    "#If accuracy of classifier > 50%,then weight is positive,\n",
    "#Else weight is negative\n",
    "def classifierWeight(error):\n",
    "\tif(error == 0):\n",
    "\t\terror = 0.0000000001\n",
    "\telif(error == 1):\n",
    "\t\terror = 1 - 0.0000000001; \n",
    "\tp = (1 - error)/error\n",
    "\treturn 0.5 * np.log(p)\n",
    "\n",
    "#calculate final output list by combining results of all classifiers\n",
    "#we pass a n x 3 array where we combine \n",
    "#y values of the 3 classifiers to get a single value for each row\n",
    "def finalOutput(classWts,y_array):\n",
    "\ty_out = []\n",
    "\tfor i in range(0,y_array.shape[0]):#1 row of test set\n",
    "\t\tyesWt = 0\n",
    "\t\tnoWt = 0\n",
    "\t\tfor j in range(1,y_array.shape[1]):\n",
    "\t\t\tif(y_array[i][j] == \"yes\"):\n",
    "\t\t\t\tyesWt += classWts[j]\n",
    "\t\t\telse:\n",
    "\t\t\t\tnoWt += classWts[j]\n",
    "\t\tif(yesWt > noWt):\n",
    "\t\t\ty_out.append(\"yes\")\n",
    "\t\telse:\n",
    "\t\t\ty_out.append(\"no\")\n",
    "\treturn y_out\n",
    "\n",
    "#update weight of each data point so that\n",
    "#incorrectly classified points have greater chance of being picked in next rounds\n",
    "def updateDataWts(wtList,y_test,y_pred,classWt):\n",
    "\tZ = 0\n",
    "\tfor i in range(0,len(wtList)):\n",
    "\t\tsign = 1\n",
    "\t\tif(y_test[i] != y_pred[i]):\n",
    "\t\t\tsign = -1\n",
    "\t\twtList[i] = wtList[i] * math.exp(-1 * sign * classWt)\n",
    "\t\tZ += wtList[i]\n",
    "\n",
    "\t#Normalize\n",
    "\tfor i in range(0,len(wtList)):\n",
    "\t\twtList[i] = wtList[i]/Z\n",
    "\t\n",
    "\treturn wtList\n",
    "\n",
    "\n",
    "###################Calling Functions################################\n",
    "#Loading data from the given csv file\n",
    "data = genfromtxt('data3_19.csv', delimiter=',', dtype = str)\n",
    "\n",
    "#Training Phase\n",
    "p = []\n",
    "indexArray = []\n",
    "replace = True\n",
    "D = data[1:,]\n",
    "for i in range(0,D.shape[0]):\n",
    "\tp.append(1/D.shape[0])\n",
    "\tindexArray.append(i)\n",
    "\n",
    "#Random Sampling\n",
    "randomSample = np.random.choice(indexArray,D.shape[0],replace,p)\n",
    "#print(len(randomSample))\n",
    "\n",
    "train = D[:]\n",
    "#print(train1.shape[0])\n",
    "for i in range(0,D.shape[0]):\n",
    "\ttrain[i] = D[randomSample[i]]\n",
    "print(train)\n",
    "\n",
    "#3 rounds of adaboost\n",
    "#3 classifiers built\n",
    "classWts = []\n",
    "y_array = []\n",
    "X = data[1:,0:3]\n",
    "# Extracting target class\n",
    "y = data[1:,3]\n",
    "y.shape = (X.shape[0],1)\n",
    "treeArray = []\n",
    "for k in range(1,4):\n",
    "\tprint(\"########################################################################\")\n",
    "\tprint(\"CLASSIFIER \" + str(k))\n",
    "\t#Extracting data labels and attributes\n",
    "\tlabels = data[0,0:3]\n",
    "\tattr = []\n",
    "\n",
    "\t\n",
    "\t#tab : to add necessary indentation\n",
    "\ttab = \"\"\n",
    "\n",
    "\t#Build decision tree\n",
    "\tX_train = train[:,0:3]\n",
    "\t\n",
    "\t#make list of all possible values of all attributes \n",
    "\tfor i in range(0,3):\n",
    "\t\tattr.append(np.unique(X[:,i]))\n",
    "\t\n",
    "\ty_train = train[:,3]\n",
    "\ty_t = train[:,3]\n",
    "\ty_train.shape = (X_train.shape[0],1)\n",
    "\troot = recursiveTree(train,X_train,y_train,attr,labels,tab)\n",
    "\ttreeArray.append(root)\n",
    "\tlabels = labels.tolist()\n",
    "\t\n",
    "\ty_pred = runClassifier(X_train,root,labels)\n",
    "\t\n",
    "\t#Accuracy calculation\n",
    "\ty_t = y_t.tolist()\n",
    "\tn_pred = len(y_pred)\t#Number of test samples\n",
    "\t\n",
    "\tcount = 0\n",
    "\tfor i in range(0,len(y_pred)):\n",
    "\t\tif(y_pred[i] == y_t[i]):\n",
    "\t\t\tcount += 1\n",
    "\t\n",
    "\t#Display accuracy\n",
    "\tprint(\"Accuracy of the Classifier \" + str(k) + \" is: \")\n",
    "\tprint(str(count/n_pred))\n",
    "\n",
    "\tE = 1 - (count/n_pred)\n",
    "\tcurr_wt = classifierWeight(E)\n",
    "\tclassWts.append(curr_wt)\n",
    "\tp = updateDataWts(p,y_train,y_pred,curr_wt)\n",
    "\n",
    "\trandomSample = np.random.choice(indexArray,D.shape[0],replace,p)\n",
    "\t\n",
    "\ttrain = D[:]\n",
    "\tfor i in range(0,D.shape[0]):\n",
    "\t\ttrain[i] = D[randomSample[i]]\n",
    "\n",
    "print(\"########################################################################\")\n",
    "print(\"COMBINED CLASSIFIER \")\n",
    "\n",
    "data_test = genfromtxt('test3_19.csv', delimiter=',', dtype = str)\n",
    "X_test = data_test[1:,0:3]\n",
    "y_test = data_test[1:,3]\n",
    "y_test = y_test.tolist()\n",
    "\n",
    "#Testing Phase\n",
    "y_p = []\n",
    "for i in range(0,3):\n",
    "\ty_p = runClassifier(X_test,treeArray[i],labels)\n",
    "\ty_array.append(y_p)\n",
    "y_array = np.asarray(y_array)\n",
    "y_array = np.transpose(y_array)\n",
    "\n",
    "y_out = finalOutput(classWts,y_array)\n",
    "#print(y_out)\n",
    "\n",
    "#Accuracy calculation\n",
    "n_test = len(y_test)#Number of test samples\n",
    "c = 0\n",
    "for i in range(0,len(y_out)):\n",
    "\tif(y_out[i] == y_test[i]):\n",
    "\t\tc += 1\n",
    "\n",
    "#Display accuracy\n",
    "print(\"Accuracy of the Combined Classifier is: \")\n",
    "print(str(c/n_test))\n",
    "\n",
    "################################END#################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
